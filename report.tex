\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{COMP-551 Kagle Competition\\
{\Large Team: Stochastic Gradient Descent into Madness}
}

\author{
\IEEEauthorblockN{Charles Alexandre Bedard}
\IEEEauthorblockA{\{email\}}
\IEEEauthorblockA{\{student id\}}
\and
\IEEEauthorblockN{Daniel Cimento}
\IEEEauthorblockA{daniel.cimento@mail.mcgill.ca}
\IEEEauthorblockA{260679318}
\and
\IEEEauthorblockN{Zi Wen Wang}
\IEEEauthorblockA{zi.w.wang@mail.mcgill.ca}
\IEEEauthorblockA{260485169}
}

\maketitle

\section{\textbf{Introduction}}

For this project, we were tasked with training classifiers to recognize hand drawn images on a modified subset of the Google ``Quick, Draw!'' dataset.

This dataset was altered with noise artifacts and various transformations to the images, so we needed to keep those modifications in mind when designing our solution.

We tackled this project by trying a variety of image pre-processing methods and using three classifiers: an SVM with a linear kernel, a feed-forward neural network, and a convolutional neural network (CNN).

Of these, we saw the best performance with the CNN, and some aspects of image pre-processing helped produce the best results.

\section{\textbf{Feature Design}}

The biggest difficulties faced by our dataset were the noise and the number of features. The sizes of the images caused training to take a long time, and the noise interfered significantly with our linear model.

Our first attempt at pre-processing involved using smoothing and erosion based filters to reduce the impact of the noise and sharpen the main shape of the image under test. In doing this, we hoped our models would be more easily able to identify the features that were relevant to the label.

Our next approach was cropping the image based on pixel density, with the hope that the actual image would stand out from the noise. By cropping the image, we would drastically reduce the number of features to speed up training and improve performance by removing excessive noise interference.

This unfortunately did not perfectly crop the images in question, and it took a very long time to pre-process the images, so we revisited this approach by using a contour-based approach, isolating the largest contiguous region of pixels and cropping around it. This was much faster than the density approach, and it provided significantly cleaner results. In addition, since the crop size was based on the input data, we were confident that our resultant size would be as minimal as feasibly possible.

\section{\textbf{Algorithms}}

\subsection{Linear SVM}

Our ``baseline'' algorithm was an SVM with a linear kernel. Given the number of features and the interference with noise, we anticipated that the performance would be suboptimal, since finding key support vectors would be challenging.

We thought SVMs would be a better baseline model than alternatives like Decision Trees and Naive Bayes, as ultimately Decision Trees were too slow to train reliably on such a high dimensionality, and Naive Bayes has independence assumptions that are too strong, given the impact contiguity of pixels has on overall structure. 

Since Naive Bayes is a probabilistic approach, it may have had an advantage in handling the random noise, but ultimately we felt that the independence assumption outweighed that benefit, and we hoped to see similar improvements just from image preprocessing.

\subsection{Neural Network}

The neural network is considered a universal function approximator, which means that with enough nodes, a two-layer neural network can approximate any function to within a certain error bound. The function we are trying to emulate is one which, after training on the data, can output class labels for images depending on whether or not a given drawing appears in the image.

The neural network model was implemented as a series of matrices, containing the weights of each layer in the network. At each layer, the previous layer's input is multiplied by the matrix and compressed using the sigmoid function, to keep the output of any given layer within a reasonable size. There is no limit on the number of neurons in any given layer, nor on the number of layers, but keeping the layers small and few improves training speeds, and adding more layers usually provides diminishing returns.

Because each layer's input is passed through to the next layer, until ultimately providing a resultant vector, we call this a ``feed forward'' approach. The largest index in our final output vector determines the label that we assign.

Like most gradually trained machine learning models, we train our neural network by minimizing a cost function, in this case minimizing $\frac{\partial C}{\partial w}$, the derivative of the cost function with respect to the weights of our model. By modifying the weights against the gradient of this derivative at each iteration, we gradually get closer to a minimal error, until our model stops improving. 

This gradient descent requires us not only to consider the influence of the last layer on our cost function, but also the layers before. We call this process of applying the changes to weights throughout the network ``back-propagation''.

\subsection{Convolutional Neural Network}

A disadvantage of regular neural network is that it does not take into account the structure of the input data. As a result, the performance when classifying categories of data like images is poor. 
A better neural network method called Convolutional Neural Network has much better performance when classifying the image data. There are several reasons for this:

First, CNN takes a 3D tensor as input and its layer can transform an input 3D volume to output 3D with some differentiable function that may or may not have parameters. 

Second, the CNN uses local receptive fields, which allow neurons to only concern themselves with a small region of interest in the image. 

Lastly, the CNN uses parameter sharing and pooling. Parameter sharing allows us to treat certain local features the same, independent of where they are found in the image. Pooling allows us to place more emphasis on whether or not a feature occurs in an image, rather than the region where the feature occurs.

The hyper-parameters in this model include the batch size of each iteration, an optimizer, the learning rate of the optimizer, and the number of epochs. How we tuned these parameters will be discussed in the methodology section.

\section{\textbf{Methodology}}

\subsection{Linear SVM}

In implementing the SVM, we used Grid Search for cross-validation and hyperparameter tuning, testing values of the hyperparameters $C$ and $tol$ over a wide range (i.e. \{$10e-5, 10e-4, \ldots 10e5$\}).

\subsection{Neural Network}

The neural networks are the most flexibile in terms of our training methods. Our feed-forward neural network was trained using K-fold cross validation, with $k = 5$.

To reach the best results, we experimented with adding more layers to the network, increasing the number of neurons in the given layers, tweaking the batch sizes, and altering the total number of epochs that we ran.

We also used the same image pre-processing described above.

\subsection{Convolutional Neural Network}

%% TODO!!!

\section{\textbf{Results}}

\subsection{Linear SVM}

For our SVM, we achieved predictably poor performance, with an accuracy of 4.366\%. Given that a hypothetical random classifier would be expected to have an accuracy of 3.22\%, this was an improvement, but not one significant enough to warrant much further exploration. From hyperparameter tuning, we didn't see any performance increase, and at more extreme hyperparameter values, we often failed to converge on our training set.

Erosion and smoothing based image pre-processing didn't show any improvement to the overall results, but cropping the images with the contour-based approach gave accuracies of 5.66\%, which was a relatively significant jump compared to our previous score.

\subsection{Neural Network}

Our neural network ultimately performed relatively poorly, at no point performing better than 20\% accuracy.

Adding layers and neurons marked a faster growth during the first few epochs, but ultimately over time it didn't provide any better performance, so we ultimately kept our layers small and sparse.

Batch sizes and epochs didn't improve the results much either, since the improvement to the model had already begun to taper off with a shorter number of epochs.

Image pre-processing helped the speed of training the model by a significant degree, and it didn't hurt the accuracy, so we settled on using image pre-processing for our feed-forward neural network.

\subsection{Convolutional Neural Network}

Ultimately, our Convolutional Neural Network gave us the best performance recorded, with an accuracy of 69.966\%. However, when we applied smoothing and cropping algorithms to our input data, we found that our performance stayed the same, and in some cases decreased. So as a whole, we achieved our best results with unprocessed input data.

\subsection{Comparison}

As a whole, for Linear SVMs, we saw performance only slightly better than a random baseline, which suggests that our data was not linearly separable enough to find significant distinctions in the input data.

Neural Networks performed better, but not by much, and the Convolutional Neural Network provided far and away the best results.

\section{\textbf{Discussion}}

We didn't have high expectations for our linear SVM, so our results weren't too surprising in that regard. However, we were a bit underwhelmed with the performance of the feed-forward neural network. The biggest con for our methodology with the feed-forward neural network is that our model was a fully-connected network, which likely allowed the noise to interfere with the model's training.

Through local receptive fields, the neurons in the CNN were able to focus specifically on various regions of the image, allowing it to distinguish the signal from the noise. There may have been a slight bias in our approach, since we put the most resources for training into the CNN, since we had anticipated it having the best results, but it doesn't seem as though the feed-forward neural network would have provided better results with more resources.

If we were to invest more in the feed-forward neural network, it would probably be the most helpful to invest more into image pre-processing, since we still ended up with quite a bit of noise in our final product.

\section{\textbf{Statement of Contributions}}

Charles made the most significant contributions to the methodology and implementation our pre-processing methods, handling the smoothing, erosion, and contour based approaches. He also contributed to the data analysis stemming from the pre-processing changes.

Daniel handled the linear SVM baseline, including hyperparameter tuning and the resulting data analysis. He also helped write the code for the feed-forward neural networkcontributed to the methodology of the pre-processing methods and contributed to writing the report.

Ziwen worked on the implementation of the Neural Network and took the initiative on the Convolutional Neural Network, handling the methodology, implementation, and data analysis.

We hereby state that all the work presented in this report is that of the authors. 

\end{document}