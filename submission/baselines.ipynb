{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the labels as numbers\n",
    "class_name_list = [\n",
    "    \"sink\",\"pear\",\"moustache\",\n",
    "    \"nose\",\"skateboard\",\"penguin\",\n",
    "    \"peanut\",\"skull\",\"panda\",\n",
    "    \"paintbrush\",\"nail\",\"apple\",\n",
    "    \"rifle\",\"mug\",\"sailboat\",\n",
    "    \"pineapple\",\"spoon\",\"rabbit\",\n",
    "    \"shovel\",\"rollerskates\",\"screwdriver\",\n",
    "    \"scorpion\",\"rhinoceros\",\"pool\",\n",
    "    \"octagon\",\"pillow\",\"parrot\",\n",
    "    \"squiggle\",\"mouth\",\"empty\",\n",
    "    \"pencil\"]\n",
    "\n",
    "label_to_num = dict(zip(class_name_list, range(0, len(class_name_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the next 3 cells are just for image pre-processing. You can ignore them if you've already seen them.\n",
    "\n",
    "# Helper methods when working with arrays\n",
    "def imagify(origin_array, size):\n",
    "    #function to turn a 1d vector into a square matrix\n",
    "    #origin_aray -> any vector\n",
    "    #size -> the size of the matrix to create\n",
    "    new_array = np.zeros((size,size))\n",
    "    for i in range (0,size):\n",
    "        for j in range (0,size):\n",
    "            new_array[i][j] = origin_array[i*size+j]\n",
    "    return new_array\n",
    "\n",
    "def de_imagify(img, size):\n",
    "    #function to turn a square matrix into a vector\n",
    "    #img -> square matrix\n",
    "    #size -> the size of the square matrix\n",
    "    new_array = np.zeros((size ** 2))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            new_array[i*size+j] = img[i][j]\n",
    "    return np.asarray(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_all_images(input_file_path, output_file_path):\n",
    "    #function to take all the images from the input_file_path, and crop them to a uniform size\n",
    "    #by default, all images are cropped and rescaled to 100,100\n",
    "    #the resulting images are saved into the output_file_path\n",
    "    #return: the size of the biggest cropped image, before rescaling\n",
    "    all_img = np.load(input_file_path, encoding='latin1')\n",
    "\n",
    "    #make an identical copy of the file, we will only modify the data of the images\n",
    "    cropped_img = all_img.copy()\n",
    "    #make a list to store the cropped images temporarily\n",
    "    cropped_list = []\n",
    "\n",
    "    #variables storing the size of the biggest image, used to resize all the samples\n",
    "    max_width = 0\n",
    "    max_height = 0\n",
    "    for i in tqdm(range(all_img.shape[0])):\n",
    "        #get the image in this row\n",
    "        img = imagify(all_img[i][1],100)\n",
    "        #make a copy that will remain unaltered\n",
    "        img_cpy = img.copy()\n",
    "        #blur the image\n",
    "        img = cv.GaussianBlur(img,(3,3),0)\n",
    "        # convert to grayscale\n",
    "        imgray = np.uint8(img * 255) \n",
    "        #convert to binary image\n",
    "        ret, thresh = cv.threshold(imgray, 20, 255, 0)\n",
    "        #get the contours in the image\n",
    "        im2, contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        #convert to rgb to have 3 channels\n",
    "        im2 = cv.cvtColor(im2, cv.COLOR_GRAY2RGB)   \n",
    "        #now get the biggest contour from the image\n",
    "        maxArea = 0\n",
    "        maxIndex = 0\n",
    "        if len(contours) != 0:\n",
    "            for i in range(len(contours)):\n",
    "                if cv.contourArea(contours[i]) > maxArea:\n",
    "                    maxArea = cv.contourArea(contours[i])\n",
    "                    maxIndex = i\n",
    "        #get the coordinates of the rectangle surrounding the shape\n",
    "        a,b,c,d = cv.boundingRect(contours[maxIndex])\n",
    "        #draw the rectangle\n",
    "        #cv.rectangle(img,(a,b),(a+c,b+d),(255),1)\n",
    "        #crop the original image\n",
    "        crop = img_cpy[b:b+d, a:a+c]\n",
    "        temp_max = np.max([c,d])\n",
    "        crop = cv.resize(crop,(100,100))\n",
    "        cropped_img[i][1] = de_imagify(crop,100)\n",
    "        cropped_list.append(crop)\n",
    "        if (c > max_width):\n",
    "            max_width = c\n",
    "        if (d > max_height):\n",
    "            max_height = d\n",
    "\n",
    "    #get the max size, i.e. biggest value between width and height\n",
    "    max_size = np.max([max_height,max_width])\n",
    "    for i in tqdm(range(cropped_img.shape[0])):\n",
    "    #for i in tqdm(range(2)):\n",
    "        #resize the array\n",
    "        np.resize(cropped_img[i][1],(max_size ** 2))\n",
    "        #cropped_img[i][1].resize(max_size)\n",
    "        img = cropped_list[i]\n",
    "        #crop the image to the max size, as a square\n",
    "        crop = cv.resize(img,(max_size,max_size))\n",
    "        #cropped_img[i][1] = de_imagify(crop,max_size)\n",
    "        cropped_img[i][1] = de_imagify(crop,max_size)\n",
    "        #crop = cv.resize(crop,(100,100))\n",
    "\n",
    "\n",
    "    np.save(output_file_path, cropped_img)\n",
    "    return max_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_all(input_file_path,output_file_path, current_size, size):\n",
    "    #function to resize all the images in a file\n",
    "    #takes the images in input_file_path and puts the resized ones in output_file_path\n",
    "    #current_size -> the current size of the square matrices representing the images\n",
    "    #size -> the wanted size of the square matrices\n",
    "    all_img = np.load(input_file_path, encoding='latin1')\n",
    "    print(all_img.shape[0])\n",
    "    all_copy = all_img.copy()\n",
    "    img_list = []\n",
    "    for i in tqdm(range(all_img.shape[0])):\n",
    "        img = imagify(all_img[i][1],current_size)\n",
    "        #resize the array\n",
    "        np.resize(all_img[i][1],(size ** 2))\n",
    "        resized_img = cv.resize(img,(size,size))\n",
    "        all_img[i][1] = de_imagify(resized_img,size)\n",
    "    np.save(output_file_path,all_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in all the labels and convert them to numbers:\n",
    "train_labels = []\n",
    "with open(\"train_labels.csv\") as label_file:\n",
    "    next(label_file)\n",
    "    for line in label_file:\n",
    "        text_label = line.split(\",\")[1].strip()\n",
    "        label = label_to_num[text_label]\n",
    "        train_labels.append(label)\n",
    "        \n",
    "training_data = np.load(\"scaled_train_images.npy\", encoding='latin1')\n",
    "\n",
    "for i in range(0, training_data.shape[0]):\n",
    "    training_data[i] = np.array([training_data[i][1], train_labels[i]])\n",
    "    \n",
    "np.save(\"formatted_train_data.npy\", training_data)\n",
    "\n",
    "Xs, ys = np.hsplit(training_data, 2)\n",
    "Xs, ys = np.stack(Xs.flatten()), ys.flatten()\n",
    "ys = ys.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that gave us the best results\n",
    "param_grid = {'C': [1.0], 'tol': [1e-4]}\n",
    "baseline_model = GridSearchCV(LinearSVC(max_iter=4000), param_grid)\n",
    "\n",
    "baseline_model.fit(Xs, ys)\n",
    "\n",
    "print(f\"Baseline model score: {baseline_model.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(\"scaled_test_images.npy\", encoding='latin1')\n",
    "\n",
    "_, test_Xs = np.hsplit(test_data, 2)\n",
    "test_Xs = np.stack(test_Xs.flatten())\n",
    "\n",
    "answers = baseline_model.predict(test_Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('submission.csv','w',) as outfile:\n",
    "    outfile.write('Id,Category\\n')\n",
    "    for (i, label) in enumerate(answers):\n",
    "        outfile.write(f\"{i},{class_name_list[label]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
